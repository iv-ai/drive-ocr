{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575d3793c994f235",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:07.181429Z",
     "start_time": "2025-03-13T20:18:06.995504Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # OCR Processor Notebook\n",
    "# ## 1. Import Dependencies\n",
    "\n",
    "# %%\n",
    "import csv\n",
    "import io\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "from PIL import Image, ImageOps\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5094663fb50b0caa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:09.362598Z",
     "start_time": "2025-03-13T20:18:09.346566Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Configuration\n",
    "\n",
    "# %%\n",
    "# Configuration Constants\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.webp', '.bmp', '.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb227acb72faf4a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:12.560663Z",
     "start_time": "2025-03-13T20:18:12.388896Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Core Functions\n",
    "\n",
    "# %%\n",
    "def authenticate_google_drive(credential_file):\n",
    "    \"\"\"Authenticate with Google Drive API\"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        credential_file, scopes=SCOPES\n",
    "    )\n",
    "    return build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "def list_files_in_folder(service, folder_id):\n",
    "    \"\"\"List all image files in a Google Drive folder with pagination support\"\"\"\n",
    "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "    page_token = None\n",
    "    files = []\n",
    "    \n",
    "    while True:\n",
    "        results = service.files().list(\n",
    "            q=query,\n",
    "            fields=\"nextPageToken, files(id, name, mimeType)\",\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "        \n",
    "        items = results.get('files', [])\n",
    "        files.extend([f for f in items if f['name'].lower().endswith(IMAGE_EXTENSIONS)])\n",
    "        \n",
    "        page_token = results.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break\n",
    "            \n",
    "    return files\n",
    "\n",
    "def get_folder_id_from_url(url):\n",
    "    \"\"\"Extract folder ID from Google Drive URL\"\"\"\n",
    "    # Handle different URL formats\n",
    "    if 'folders' in url:\n",
    "        return url.split('folders/')[-1].split('?')[0]\n",
    "    elif 'id=' in url:\n",
    "        return url.split('id=')[-1].split('&')[0]\n",
    "    return url\n",
    "\n",
    "def list_all_files_recursive(service, folder_id):\n",
    "    \"\"\"Recursively list all image files in a folder and its subfolders\"\"\"\n",
    "    all_files = []\n",
    "    \n",
    "    # First get all files in current folder\n",
    "    files = list_files_in_folder(service, folder_id)\n",
    "    all_files.extend(files)\n",
    "    \n",
    "    # Then get all subfolders\n",
    "    query = f\"'{folder_id}' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
    "    page_token = None\n",
    "    \n",
    "    while True:\n",
    "        results = service.files().list(\n",
    "            q=query,\n",
    "            fields=\"nextPageToken, files(id, name)\",\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "        \n",
    "        folders = results.get('files', [])\n",
    "        \n",
    "        # Recursively process each subfolder\n",
    "        for folder in folders:\n",
    "            subfolder_files = list_all_files_recursive(service, folder['id'])\n",
    "            all_files.extend(subfolder_files)\n",
    "        \n",
    "        page_token = results.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def download_file(service, file_id, filename, destination_folder):\n",
    "    \"\"\"Download file from Google Drive if not exists\"\"\"\n",
    "    dest_path = Path(destination_folder) / filename\n",
    "    if dest_path.exists():\n",
    "        return\n",
    "\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "\n",
    "    with io.BytesIO() as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "        \n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(fh.getbuffer())\n",
    "\n",
    "def process_image(img):\n",
    "    \"\"\"Enhance image for OCR processing\"\"\"\n",
    "    if img.mode == 'RGBA':\n",
    "        background = Image.new('RGB', img.size, (255, 255, 255))\n",
    "        background.paste(img, mask=img.split()[-1])\n",
    "        img = background\n",
    "\n",
    "    gray = img.convert('L')\n",
    "    processed = gray.point(lambda x: ((x / 255) ** 3 * 255))  # Gamma\n",
    "    processed = processed.point(lambda x: 255 if x > 128 else 0)  # Threshold\n",
    "    return ImageOps.invert(processed)\n",
    "\n",
    "def ocr_image(image):\n",
    "    \"\"\"Perform OCR on PIL Image\"\"\"\n",
    "    data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    \n",
    "    confidences = [float(c) for c, t in zip(data['conf'], data['text'])\n",
    "                  if t.strip() and float(c) >= 0]\n",
    "    avg_confidence = round(sum(confidences)/len(confidences), 2) if confidences else 0\n",
    "    return text, avg_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa505c87e229b69",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:17.304967Z",
     "start_time": "2025-03-13T20:18:17.240084Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Processing Functions\n",
    "\n",
    "# %%\n",
    "def process_files(file_list, service=None, force=False):\n",
    "    \"\"\"Process files (Drive or local)\"\"\"\n",
    "    Path('transcripts').mkdir(exist_ok=True)\n",
    "    \n",
    "    for file_info in file_list:\n",
    "        try:\n",
    "            if isinstance(file_info, dict):  # Google Drive file\n",
    "                filename = file_info['name']\n",
    "                file_id = file_info['id']\n",
    "                source_path = Path('downloaded_images') / filename\n",
    "                download_file(service, file_id, filename, 'downloaded_images')\n",
    "            else:  # Local file\n",
    "                filename = file_info.name\n",
    "                source_path = file_info\n",
    "\n",
    "            transcript_path = Path('transcripts') / f\"{source_path.stem}.txt\"\n",
    "            if not force and transcript_path.exists():\n",
    "                print(f\"Skipping {filename} - transcript exists\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nProcessing {filename}\")\n",
    "            \n",
    "            with Image.open(source_path) as img:\n",
    "                processed_img = process_image(img)\n",
    "                text, confidence = ocr_image(processed_img)\n",
    "                \n",
    "                print(f\"OCR Confidence: {confidence}%\")\n",
    "                with open(transcript_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(text)\n",
    "                print(f\"Saved transcript to {transcript_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "def export_csv(output_file):\n",
    "    \"\"\"Export transcripts to CSV\"\"\"\n",
    "    transcript_dir = Path('transcripts')\n",
    "    downloaded_dir = Path('downloaded_images')\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for transcript_path in transcript_dir.glob('*.txt'):\n",
    "        try:\n",
    "            stem = transcript_path.stem\n",
    "            image_path = None\n",
    "            original_filename = None\n",
    "            \n",
    "            for ext in IMAGE_EXTENSIONS:\n",
    "                possible_path = downloaded_dir / f\"{stem}{ext}\"\n",
    "                if possible_path.exists():\n",
    "                    image_path = possible_path\n",
    "                    original_filename = possible_path.name\n",
    "                    break\n",
    "            \n",
    "            with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                transcript_text = f.read()\n",
    "            \n",
    "            records.append({\n",
    "                'original_file_name': original_filename or 'Unknown',\n",
    "                'file_path': str(image_path) if image_path else 'Not found',\n",
    "                'transcript_text': transcript_text\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {transcript_path.name}: {str(e)}\")\n",
    "    \n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, \n",
    "            fieldnames=['original_file_name', 'file_path', 'transcript_text'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "    \n",
    "    print(f\"Exported {len(records)} transcripts to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a6194f6fbc2aba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:21.114393Z",
     "start_time": "2025-03-13T20:18:21.110074Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Execution Control\n",
    "# \n",
    "# Choose your operation mode:\n",
    "\n",
    "# %%\n",
    "# Configuration Cell - Edit these values before running\n",
    "MODE = 'export'  # Choose from: 'drive', 'local', 'export'\n",
    "FORCE_REPROCESS = False  # Set to True to overwrite existing transcripts\n",
    "#GOOGLE_FOLDER_URL = 'https://drive.google.com/drive/folders/18RaLotdAd5ggl9g2MDXfsnVSjJxOWmw5'  # For drive mode\n",
    "GOOGLE_FOLDER_URL = 'https://drive.google.com/drive/folders/1v_F3oshp4o8Pd2ivnn_biJVdRKL0wZ05'\n",
    "CREDENTIALS_FILE = 'credentials/testing-451622-d2bb9ea8367e.json'  # For drive mode\n",
    "CSV_OUTPUT_FILE = 'transcripts.csv'  # For export mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b125a1456c6b3c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T20:18:23.125830Z",
     "start_time": "2025-03-13T20:18:23.118495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 0 transcripts to transcripts.csv\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Run Selected Operation\n",
    "\n",
    "# %%\n",
    "if MODE == 'drive':\n",
    "    service = authenticate_google_drive(CREDENTIALS_FILE)\n",
    "    folder_id = get_folder_id_from_url(GOOGLE_FOLDER_URL)\n",
    "    files = list_all_files_recursive(service, folder_id)\n",
    "    print(f\"Found {len(files)} images in Google Drive and its subfolders\")\n",
    "    process_files(files, service=service, force=FORCE_REPROCESS)\n",
    "    \n",
    "elif MODE == 'local':\n",
    "    image_files = []\n",
    "    for ext in IMAGE_EXTENSIONS:\n",
    "        image_files.extend(Path('downloaded_images').glob(f'*{ext}'))\n",
    "    print(f\"Found {len(image_files)} local images\")\n",
    "    process_files(image_files, force=FORCE_REPROCESS)\n",
    "    \n",
    "elif MODE == 'export':\n",
    "    export_csv(CSV_OUTPUT_FILE)\n",
    "    \n",
    "else:\n",
    "    print(\"Invalid mode selected. Please choose from: 'drive', 'local', 'export'\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
